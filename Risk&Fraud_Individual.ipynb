{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to a competition powered by AutoDSC for Data Science Challenges! By Prof. Manoel Gadi!\n",
    "\n",
    "PLEASE DO NOT RENAME THIS FILE!\n",
    "\n",
    "\n",
    "Simply run this code and start competing today in the competion: 6aQ6IxU7Va\n",
    "\n",
    "6aQ6IxU7Va details:\n",
    " - Description / Descripción: FRAUD MODELLING CHALLENGE - Predict which Credit Card Application is legitimate and which belongs to a fraudster instead.\n",
    " - Maximum number of daily attempts / Número máximo de intentos diarios: 10000\n",
    " - Creation date / Fecha de creación: 2020-06-10 11:36:52\n",
    " - Starting date / Fecha de inicio: 2023-04-10 00:00:00\n",
    " - Ending date / Fecha de fin: 2023-05-29 23:59:00\n",
    " - Minimum time between prediction submissions / Tiempo mínimo entre envíos de predicciones: 30\n",
    "\n",
    "Of couse, to win the competition you should improve the starting model! So let's get to work!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTING LIBRARIES...\n",
      "LOADING DATASETS...\n"
     ]
    }
   ],
   "source": [
    "print (\"IMPORTING LIBRARIES...\")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print (\"LOADING DATASETS...\")\n",
    "try: # reading train csv from local file\n",
    "    df_train = pd.read_csv(\"mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "    df_train.head()\n",
    "except: # reading train csv from the internet if it is the first time\n",
    "    import urllib\n",
    "    csv_train = urllib.request.urlopen(\"http://manoelutad.pythonanywhere.com/static/uploads/mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "    csv_train_content = csv_train.read()\n",
    "    with open(\"mfalonso__6aQ6IxU7Va__train.csv\", 'wb') as f:\n",
    "            f.write(csv_train_content)\n",
    "    df_train = pd.read_csv(\"mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "\n",
    "    \n",
    "try: # reading test csv from local file\n",
    "    df_test = pd.read_csv(\"mfalonso__6aQ6IxU7Va__test.csv\")\n",
    "    df_test.head()\n",
    "except: # reading test csv from the internet if it is the first time\n",
    "    import urllib\n",
    "    csv_test = urllib.request.urlopen(\"http://manoelutad.pythonanywhere.com/static/uploads/mfalonso__6aQ6IxU7Va__test.csv\")\n",
    "    csv_test_content = csv_test.read()\n",
    "    with open(\"mfalonso__6aQ6IxU7Va__test.csv\", 'wb') as f:\n",
    "            f.write(csv_test_content)\n",
    "    df_test = pd.read_csv(\"mfalonso__6aQ6IxU7Va__test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DOING MY TRANSFORMATIONS...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 1: DOING MY TRANSFORMATIONS...\")\n",
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: SELECTING CHARACTERISTICS TO ENTER INTO THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 2: SELECTING CHARACTERISTICS TO ENTER INTO THE MODEL...\")\n",
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)\n",
    "\n",
    "output_var = df_train.columns[-1]\n",
    "in_model = get_specific_columns(df_train, [\"float64\", \"int64\"], [output_var], ignore_target = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "X_train = df_train[in_model]\n",
    "y_train = df_train[output_var]\n",
    "X_test = df_test[in_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Grid Search for Hyperparameter Tunning (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 75, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "        # Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "   'n_estimators': [500, 1000, 1500],  # Number of trees in the forest\n",
    "    'max_depth': [75, 80, 90],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2]\n",
    "     # Weighting strategy for the classes\n",
    "}\n",
    "        # Create the model Classifier to be used (either the tree or the random forest) \n",
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "        # Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "        \n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "        # Use the best model for prediction\n",
    "best_model = grid_search.best_estimator_\n",
    "pred_test = best_model.predict_proba(X_test)[:, 1]\n",
    "pred_train = best_model.predict_proba(X_train)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Testing SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.9/site-packages (0.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.2.0)\n",
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "clf = RandomForestClassifier(random_state=80, class_weight='balanced')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "fitted_model = clf.fit(X_train_resampled, y_train_resampled)\n",
    "pred_train = fitted_model.predict_proba(X_train_resampled)[:,1]\n",
    "pred_test = fitted_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print (\"STEP 3: DEVELOPING THE MODEL...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "fitted_model = clf.fit(X_train, y_train)\n",
    "pred_train = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test = fitted_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print (\"STEP 3: DEVELOPING THE MODEL...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0, class_weight=\"balanced\") \n",
    "fitted_model = clf.fit(X_train, y_train)\n",
    "pred_train = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test = fitted_model.predict_proba(X_test)[:,1]\n",
    "#gives error, cannot submit these values\n",
    "\n",
    "print (\"STEP 3: DEVELOPING THE MODEL...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "\n",
    "fitted_model = clf.fit(X_train, y_train)\n",
    "pred_train = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test  = fitted_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "params = clf.get_params()\n",
    "\n",
    "for param, value in params.items():\n",
    "    print(f'{param}: {value}')\n",
    "    \n",
    "print (\"STEP 3: DEVELOPING THE MODEL...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6: Naive Bayes (worst model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "fitted_model = clf.fit(X_train, y_train)\n",
    "pred_train = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test  = fitted_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print (\"STEP 3: DEVELOPING THE MODEL...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: ASSESSING THE MODEL...\n",
      "GINI DEVELOPMENT= 0.44455834114339265\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 4: ASSESSING THE MODEL...\")\n",
    "# CALCULATING GINI PERFORMANCE ON DEVELOPMENT SAMPLE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "gini_score = 2*roc_auc_score(y_train, pred_train)-1\n",
    "print (\"GINI DEVELOPMENT=\", gini_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT IS GINI?\n",
    "* watch this video for reference: https://youtu.be/MiBUBVUC8kE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: SUBMITTING THE RESULTS... DO NOT CHANGE THIS PART!\n",
      "RESULT SUBMISSION:  ERROR: enviado despues de fecha de cierre\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 5: SUBMITTING THE RESULTS... DO NOT CHANGE THIS PART!\")\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "df_test['pred'] = pred_test\n",
    "df_test['id'] = df_test.iloc[:,0]\n",
    "df_test_tosend = df_test[['id','pred']]\n",
    "\n",
    "filename = \"df_test_tosend.csv\"\n",
    "df_test_tosend.to_csv(filename, sep=',')\n",
    "url = 'http://manoelutad.pythonanywhere.com/uploadpredictions/6aQ6IxU7Va'\n",
    "files = {'file': (filename, open(filename, 'rb')),\n",
    "         'ipynbcode': ('6aQ6IxU7Va.ipynb', open('6aQ6IxU7Va.ipynb', 'rb'))}\n",
    "\n",
    "\n",
    "#rsub = requests.post(url, files=files)\n",
    "rsub = requests.post(url, files=files, auth=HTTPBasicAuth(\"joaoferris\", \"sha256$iu5U38YE$244190648eceab7fa04d46bb1e9cb62e199ef0ef218134abc0b8512cf2d0ffbf\"))\n",
    "resp_str = str(rsub.text)\n",
    "print (\"RESULT SUBMISSION: \", resp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: SUBMITTING THE RESULTS... DO NOT CHANGE THIS PART!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19395685877991292"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"STEP 5: SUBMITTING THE RESULTS... DO NOT CHANGE THIS PART!\")\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "df_test['pred'] = pred_test\n",
    "df_test['id'] = df_test.iloc[:,0]\n",
    "df_test_tosend = df_test[['id','pred']]\n",
    "\n",
    "filename = \"df_test_tosend.csv\"\n",
    "df_test_tosend.to_csv(filename, sep=',')\n",
    "url = 'http://manoelutad.pythonanywhere.com/uploadpredictions/6aQ6IxU7Va'\n",
    "files = {'file': (filename, open(filename, 'rb')),\n",
    "         'ipynbcode': ('6aQ6IxU7Va.ipynb', open('6aQ6IxU7Va.ipynb', 'rb'))}\n",
    "\n",
    "df_test['pred'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
